{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1221fda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73ba192",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9331658",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('sonar3.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10da7bb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    111\n",
       "0     97\n",
       "Name: 60, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[60].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce52d910",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[:,:60]\n",
    "y = df.iloc[:,60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbccb63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36da6c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07e5b5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23e03b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(24,input_dim=60,activation='relu'))\n",
    "model.add(Dense(10,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d3ef1406",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e08e41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4350845b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "21/21 [==============================] - 1s 1ms/step - loss: 0.6959 - accuracy: 0.5096\n",
      "Epoch 2/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6868 - accuracy: 0.6058\n",
      "Epoch 3/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6815 - accuracy: 0.6058\n",
      "Epoch 4/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6780 - accuracy: 0.5769\n",
      "Epoch 5/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6739 - accuracy: 0.6683\n",
      "Epoch 6/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6674 - accuracy: 0.6298\n",
      "Epoch 7/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6618 - accuracy: 0.6587\n",
      "Epoch 8/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6541 - accuracy: 0.6202\n",
      "Epoch 9/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6431 - accuracy: 0.7404\n",
      "Epoch 10/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6348 - accuracy: 0.6250\n",
      "Epoch 11/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6252 - accuracy: 0.7548\n",
      "Epoch 12/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6146 - accuracy: 0.7404\n",
      "Epoch 13/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5970 - accuracy: 0.7452\n",
      "Epoch 14/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5834 - accuracy: 0.7500\n",
      "Epoch 15/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5756 - accuracy: 0.7837\n",
      "Epoch 16/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5637 - accuracy: 0.7788\n",
      "Epoch 17/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5568 - accuracy: 0.8269\n",
      "Epoch 18/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5567 - accuracy: 0.8173\n",
      "Epoch 19/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5326 - accuracy: 0.7692\n",
      "Epoch 20/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5256 - accuracy: 0.8462\n",
      "Epoch 21/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.5200 - accuracy: 0.8173\n",
      "Epoch 22/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.8269\n",
      "Epoch 23/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.4954 - accuracy: 0.8317\n",
      "Epoch 24/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.4871 - accuracy: 0.8462\n",
      "Epoch 25/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.4835 - accuracy: 0.8606\n",
      "Epoch 26/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.4747 - accuracy: 0.8750\n",
      "Epoch 27/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.4659 - accuracy: 0.8269\n",
      "Epoch 28/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.4609 - accuracy: 0.8798\n",
      "Epoch 29/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.4523 - accuracy: 0.8702\n",
      "Epoch 30/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.4481 - accuracy: 0.8606\n",
      "Epoch 31/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.4436 - accuracy: 0.8510\n",
      "Epoch 32/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.4343 - accuracy: 0.8990\n",
      "Epoch 33/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.4271 - accuracy: 0.8942\n",
      "Epoch 34/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.4257 - accuracy: 0.9087\n",
      "Epoch 35/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.4167 - accuracy: 0.8942\n",
      "Epoch 36/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.4089 - accuracy: 0.9087\n",
      "Epoch 37/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.4099 - accuracy: 0.8894\n",
      "Epoch 38/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.4081 - accuracy: 0.8798\n",
      "Epoch 39/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.3973 - accuracy: 0.8942\n",
      "Epoch 40/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.3977 - accuracy: 0.8990\n",
      "Epoch 41/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.4024 - accuracy: 0.8846\n",
      "Epoch 42/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.3921 - accuracy: 0.8942\n",
      "Epoch 43/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.3778 - accuracy: 0.9231\n",
      "Epoch 44/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3724 - accuracy: 0.9087\n",
      "Epoch 45/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.3723 - accuracy: 0.9135\n",
      "Epoch 46/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.3610 - accuracy: 0.9279\n",
      "Epoch 47/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.3712 - accuracy: 0.8942\n",
      "Epoch 48/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.3567 - accuracy: 0.9231\n",
      "Epoch 49/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.3513 - accuracy: 0.9231\n",
      "Epoch 50/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.3487 - accuracy: 0.9279\n",
      "Epoch 51/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.3410 - accuracy: 0.9231\n",
      "Epoch 52/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.3395 - accuracy: 0.9327\n",
      "Epoch 53/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.3318 - accuracy: 0.9375\n",
      "Epoch 54/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.3470 - accuracy: 0.9135\n",
      "Epoch 55/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.3316 - accuracy: 0.9327\n",
      "Epoch 56/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.3216 - accuracy: 0.9327\n",
      "Epoch 57/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.3203 - accuracy: 0.9327\n",
      "Epoch 58/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.3175 - accuracy: 0.9327\n",
      "Epoch 59/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.3133 - accuracy: 0.9327\n",
      "Epoch 60/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.3163 - accuracy: 0.9375\n",
      "Epoch 61/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.3073 - accuracy: 0.9375\n",
      "Epoch 62/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.3033 - accuracy: 0.9375\n",
      "Epoch 63/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.3018 - accuracy: 0.9471\n",
      "Epoch 64/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2970 - accuracy: 0.9375\n",
      "Epoch 65/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2938 - accuracy: 0.9423\n",
      "Epoch 66/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2925 - accuracy: 0.9375\n",
      "Epoch 67/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2886 - accuracy: 0.9327\n",
      "Epoch 68/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2838 - accuracy: 0.9471\n",
      "Epoch 69/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2801 - accuracy: 0.9423\n",
      "Epoch 70/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2761 - accuracy: 0.9423\n",
      "Epoch 71/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2725 - accuracy: 0.9423\n",
      "Epoch 72/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.2740 - accuracy: 0.9375\n",
      "Epoch 73/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.2753 - accuracy: 0.9471\n",
      "Epoch 74/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.2659 - accuracy: 0.9423\n",
      "Epoch 75/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2648 - accuracy: 0.9471\n",
      "Epoch 76/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2618 - accuracy: 0.9471\n",
      "Epoch 77/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2602 - accuracy: 0.9423\n",
      "Epoch 78/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2597 - accuracy: 0.9519\n",
      "Epoch 79/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2592 - accuracy: 0.9423\n",
      "Epoch 80/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2561 - accuracy: 0.9471\n",
      "Epoch 81/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2496 - accuracy: 0.9519\n",
      "Epoch 82/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2503 - accuracy: 0.9471\n",
      "Epoch 83/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2426 - accuracy: 0.9567\n",
      "Epoch 84/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2405 - accuracy: 0.9567\n",
      "Epoch 85/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2439 - accuracy: 0.9519\n",
      "Epoch 86/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2377 - accuracy: 0.9615\n",
      "Epoch 87/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2349 - accuracy: 0.9615\n",
      "Epoch 88/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2436 - accuracy: 0.9519\n",
      "Epoch 89/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2318 - accuracy: 0.9567\n",
      "Epoch 90/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2289 - accuracy: 0.9567\n",
      "Epoch 91/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2255 - accuracy: 0.9519\n",
      "Epoch 92/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2296 - accuracy: 0.9519\n",
      "Epoch 93/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2325 - accuracy: 0.9615\n",
      "Epoch 94/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2298 - accuracy: 0.9567\n",
      "Epoch 95/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2166 - accuracy: 0.9567\n",
      "Epoch 96/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2220 - accuracy: 0.9519\n",
      "Epoch 97/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2126 - accuracy: 0.9663\n",
      "Epoch 98/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2118 - accuracy: 0.9567\n",
      "Epoch 99/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2175 - accuracy: 0.9567\n",
      "Epoch 100/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2081 - accuracy: 0.9615\n",
      "Epoch 101/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2060 - accuracy: 0.9615\n",
      "Epoch 102/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2150 - accuracy: 0.9567\n",
      "Epoch 103/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2075 - accuracy: 0.9615\n",
      "Epoch 104/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1980 - accuracy: 0.9615\n",
      "Epoch 105/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1951 - accuracy: 0.9663\n",
      "Epoch 106/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1981 - accuracy: 0.9567\n",
      "Epoch 107/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1972 - accuracy: 0.9615\n",
      "Epoch 108/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1908 - accuracy: 0.9663\n",
      "Epoch 109/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1900 - accuracy: 0.9663\n",
      "Epoch 110/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1873 - accuracy: 0.9615\n",
      "Epoch 111/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1827 - accuracy: 0.9712\n",
      "Epoch 112/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1871 - accuracy: 0.9615\n",
      "Epoch 113/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1848 - accuracy: 0.9663\n",
      "Epoch 114/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1842 - accuracy: 0.9712\n",
      "Epoch 115/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1845 - accuracy: 0.9663\n",
      "Epoch 116/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1798 - accuracy: 0.9712\n",
      "Epoch 117/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1769 - accuracy: 0.9712\n",
      "Epoch 118/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1730 - accuracy: 0.9663\n",
      "Epoch 119/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1714 - accuracy: 0.9712\n",
      "Epoch 120/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1692 - accuracy: 0.9712\n",
      "Epoch 121/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1690 - accuracy: 0.9712\n",
      "Epoch 122/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1678 - accuracy: 0.9712\n",
      "Epoch 123/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1679 - accuracy: 0.9663\n",
      "Epoch 124/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1644 - accuracy: 0.9712\n",
      "Epoch 125/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1696 - accuracy: 0.9712\n",
      "Epoch 126/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1619 - accuracy: 0.9712\n",
      "Epoch 127/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1612 - accuracy: 0.9712\n",
      "Epoch 128/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1618 - accuracy: 0.9712\n",
      "Epoch 129/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1602 - accuracy: 0.9712\n",
      "Epoch 130/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1606 - accuracy: 0.9712\n",
      "Epoch 131/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1582 - accuracy: 0.9712\n",
      "Epoch 132/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1564 - accuracy: 0.9712\n",
      "Epoch 133/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1574 - accuracy: 0.9712\n",
      "Epoch 134/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1544 - accuracy: 0.9712\n",
      "Epoch 135/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1601 - accuracy: 0.9712\n",
      "Epoch 136/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1573 - accuracy: 0.9712\n",
      "Epoch 137/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1534 - accuracy: 0.9712\n",
      "Epoch 138/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1523 - accuracy: 0.9712\n",
      "Epoch 139/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1527 - accuracy: 0.9712\n",
      "Epoch 140/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1508 - accuracy: 0.9712\n",
      "Epoch 141/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1524 - accuracy: 0.9712\n",
      "Epoch 142/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1494 - accuracy: 0.9712\n",
      "Epoch 143/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1482 - accuracy: 0.9712\n",
      "Epoch 144/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1461 - accuracy: 0.9712\n",
      "Epoch 145/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1453 - accuracy: 0.9712\n",
      "Epoch 146/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1444 - accuracy: 0.9712\n",
      "Epoch 147/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1444 - accuracy: 0.9712\n",
      "Epoch 148/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1437 - accuracy: 0.9712\n",
      "Epoch 149/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1439 - accuracy: 0.9712\n",
      "Epoch 150/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1445 - accuracy: 0.9712\n",
      "Epoch 151/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1425 - accuracy: 0.9712\n",
      "Epoch 152/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1408 - accuracy: 0.9712\n",
      "Epoch 153/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1410 - accuracy: 0.9712\n",
      "Epoch 154/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1402 - accuracy: 0.9712\n",
      "Epoch 155/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1396 - accuracy: 0.9712\n",
      "Epoch 156/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1387 - accuracy: 0.9712\n",
      "Epoch 157/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1380 - accuracy: 0.9712\n",
      "Epoch 158/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1375 - accuracy: 0.9712\n",
      "Epoch 159/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1379 - accuracy: 0.9712\n",
      "Epoch 160/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1367 - accuracy: 0.9712\n",
      "Epoch 161/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1376 - accuracy: 0.9712\n",
      "Epoch 162/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1361 - accuracy: 0.9712\n",
      "Epoch 163/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1352 - accuracy: 0.9712\n",
      "Epoch 164/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1371 - accuracy: 0.9712\n",
      "Epoch 165/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1344 - accuracy: 0.9712\n",
      "Epoch 166/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1377 - accuracy: 0.9712\n",
      "Epoch 167/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1333 - accuracy: 0.9712\n",
      "Epoch 168/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1334 - accuracy: 0.9712\n",
      "Epoch 169/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1325 - accuracy: 0.9712\n",
      "Epoch 170/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1320 - accuracy: 0.9712\n",
      "Epoch 171/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1315 - accuracy: 0.9712\n",
      "Epoch 172/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1329 - accuracy: 0.9712\n",
      "Epoch 173/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1321 - accuracy: 0.9712\n",
      "Epoch 174/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1305 - accuracy: 0.9712\n",
      "Epoch 175/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1304 - accuracy: 0.9712\n",
      "Epoch 176/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1297 - accuracy: 0.9712\n",
      "Epoch 177/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1292 - accuracy: 0.9712\n",
      "Epoch 178/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1293 - accuracy: 0.9712\n",
      "Epoch 179/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1290 - accuracy: 0.9712\n",
      "Epoch 180/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1288 - accuracy: 0.9712\n",
      "Epoch 181/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1281 - accuracy: 0.9712\n",
      "Epoch 182/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1279 - accuracy: 0.9712\n",
      "Epoch 183/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1276 - accuracy: 0.9712\n",
      "Epoch 184/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1272 - accuracy: 0.9712\n",
      "Epoch 185/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1269 - accuracy: 0.9712\n",
      "Epoch 186/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1264 - accuracy: 0.9712\n",
      "Epoch 187/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1266 - accuracy: 0.9712\n",
      "Epoch 188/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1264 - accuracy: 0.9712\n",
      "Epoch 189/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1262 - accuracy: 0.9712\n",
      "Epoch 190/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1260 - accuracy: 0.9712\n",
      "Epoch 191/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1256 - accuracy: 0.9712\n",
      "Epoch 192/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1261 - accuracy: 0.9712\n",
      "Epoch 193/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1262 - accuracy: 0.9712\n",
      "Epoch 194/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1248 - accuracy: 0.9712\n",
      "Epoch 195/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1246 - accuracy: 0.9712\n",
      "Epoch 196/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1242 - accuracy: 0.9712\n",
      "Epoch 197/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1240 - accuracy: 0.9712\n",
      "Epoch 198/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1237 - accuracy: 0.9712\n",
      "Epoch 199/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1241 - accuracy: 0.9712\n",
      "Epoch 200/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1234 - accuracy: 0.9712\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x, y, epochs=200, batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9130f32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "35c8b82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "21e0b07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(24,input_dim=60,activation='relu'))\n",
    "model.add(Dense(10,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "599c2c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "15/15 [==============================] - 1s 1ms/step - loss: 0.7099 - accuracy: 0.4552\n",
      "Epoch 2/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6760 - accuracy: 0.5793\n",
      "Epoch 3/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6645 - accuracy: 0.6000\n",
      "Epoch 4/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6569 - accuracy: 0.6138\n",
      "Epoch 5/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6454 - accuracy: 0.6483\n",
      "Epoch 6/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6364 - accuracy: 0.6897\n",
      "Epoch 7/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6285 - accuracy: 0.7034\n",
      "Epoch 8/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6177 - accuracy: 0.7379\n",
      "Epoch 9/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6058 - accuracy: 0.7379\n",
      "Epoch 10/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5937 - accuracy: 0.7724\n",
      "Epoch 11/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.5818 - accuracy: 0.7655\n",
      "Epoch 12/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.5750 - accuracy: 0.7724\n",
      "Epoch 13/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.5601 - accuracy: 0.8000\n",
      "Epoch 14/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.5459 - accuracy: 0.7862\n",
      "Epoch 15/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.5385 - accuracy: 0.7862\n",
      "Epoch 16/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.5220 - accuracy: 0.7931\n",
      "Epoch 17/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5113 - accuracy: 0.8069\n",
      "Epoch 18/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4987 - accuracy: 0.7862\n",
      "Epoch 19/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4925 - accuracy: 0.7793\n",
      "Epoch 20/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4909 - accuracy: 0.8069\n",
      "Epoch 21/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4805 - accuracy: 0.7862\n",
      "Epoch 22/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.8345\n",
      "Epoch 23/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.7931\n",
      "Epoch 24/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.4343 - accuracy: 0.8414\n",
      "Epoch 25/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.4254 - accuracy: 0.8138\n",
      "Epoch 26/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.4154 - accuracy: 0.8414\n",
      "Epoch 27/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.4112 - accuracy: 0.8414\n",
      "Epoch 28/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.4031 - accuracy: 0.8345\n",
      "Epoch 29/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.3926 - accuracy: 0.8414\n",
      "Epoch 30/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.3914 - accuracy: 0.8483\n",
      "Epoch 31/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.3859 - accuracy: 0.8414\n",
      "Epoch 32/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.3776 - accuracy: 0.8552\n",
      "Epoch 33/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.3674 - accuracy: 0.8759\n",
      "Epoch 34/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.3651 - accuracy: 0.8483\n",
      "Epoch 35/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.3587 - accuracy: 0.8414\n",
      "Epoch 36/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.3544 - accuracy: 0.8759\n",
      "Epoch 37/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.3424 - accuracy: 0.8759\n",
      "Epoch 38/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.3472 - accuracy: 0.8690\n",
      "Epoch 39/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.3407 - accuracy: 0.8345\n",
      "Epoch 40/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.3321 - accuracy: 0.8759\n",
      "Epoch 41/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3230 - accuracy: 0.8828\n",
      "Epoch 42/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3199 - accuracy: 0.8897\n",
      "Epoch 43/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3153 - accuracy: 0.8966\n",
      "Epoch 44/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3117 - accuracy: 0.8897\n",
      "Epoch 45/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3085 - accuracy: 0.8828\n",
      "Epoch 46/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3085 - accuracy: 0.8483\n",
      "Epoch 47/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.3180 - accuracy: 0.8621\n",
      "Epoch 48/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2981 - accuracy: 0.8759\n",
      "Epoch 49/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2954 - accuracy: 0.8828\n",
      "Epoch 50/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2858 - accuracy: 0.8897\n",
      "Epoch 51/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2880 - accuracy: 0.8897\n",
      "Epoch 52/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2788 - accuracy: 0.9034\n",
      "Epoch 53/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2751 - accuracy: 0.9241\n",
      "Epoch 54/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2694 - accuracy: 0.9172\n",
      "Epoch 55/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2704 - accuracy: 0.9034\n",
      "Epoch 56/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2610 - accuracy: 0.9172\n",
      "Epoch 57/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2584 - accuracy: 0.9172\n",
      "Epoch 58/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2528 - accuracy: 0.9172\n",
      "Epoch 59/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2509 - accuracy: 0.9241\n",
      "Epoch 60/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2445 - accuracy: 0.9310\n",
      "Epoch 61/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2458 - accuracy: 0.9172\n",
      "Epoch 62/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2436 - accuracy: 0.9172\n",
      "Epoch 63/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2440 - accuracy: 0.9103\n",
      "Epoch 64/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2392 - accuracy: 0.9241\n",
      "Epoch 65/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2297 - accuracy: 0.9379\n",
      "Epoch 66/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2369 - accuracy: 0.9172\n",
      "Epoch 67/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2298 - accuracy: 0.9172\n",
      "Epoch 68/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2206 - accuracy: 0.9448\n",
      "Epoch 69/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2175 - accuracy: 0.9310\n",
      "Epoch 70/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2227 - accuracy: 0.9379\n",
      "Epoch 71/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2175 - accuracy: 0.9241\n",
      "Epoch 72/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2100 - accuracy: 0.9310\n",
      "Epoch 73/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2109 - accuracy: 0.9379\n",
      "Epoch 74/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2113 - accuracy: 0.9517\n",
      "Epoch 75/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2085 - accuracy: 0.9172\n",
      "Epoch 76/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2052 - accuracy: 0.9448\n",
      "Epoch 77/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2006 - accuracy: 0.9241\n",
      "Epoch 78/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1969 - accuracy: 0.9517\n",
      "Epoch 79/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1924 - accuracy: 0.9448\n",
      "Epoch 80/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1956 - accuracy: 0.9379\n",
      "Epoch 81/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1882 - accuracy: 0.9517\n",
      "Epoch 82/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1864 - accuracy: 0.9517\n",
      "Epoch 83/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1829 - accuracy: 0.9448\n",
      "Epoch 84/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1880 - accuracy: 0.9103\n",
      "Epoch 85/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1869 - accuracy: 0.9448\n",
      "Epoch 86/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1794 - accuracy: 0.9517\n",
      "Epoch 87/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1763 - accuracy: 0.9448\n",
      "Epoch 88/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1722 - accuracy: 0.9517\n",
      "Epoch 89/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1698 - accuracy: 0.9586\n",
      "Epoch 90/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1712 - accuracy: 0.9586\n",
      "Epoch 91/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1669 - accuracy: 0.9517\n",
      "Epoch 92/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1723 - accuracy: 0.9517\n",
      "Epoch 93/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1708 - accuracy: 0.9586\n",
      "Epoch 94/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1670 - accuracy: 0.9448\n",
      "Epoch 95/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1633 - accuracy: 0.9448\n",
      "Epoch 96/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1562 - accuracy: 0.9586\n",
      "Epoch 97/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1718 - accuracy: 0.9448\n",
      "Epoch 98/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1614 - accuracy: 0.9586\n",
      "Epoch 99/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1525 - accuracy: 0.9655\n",
      "Epoch 100/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1513 - accuracy: 0.9586\n",
      "Epoch 101/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1487 - accuracy: 0.9724\n",
      "Epoch 102/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1452 - accuracy: 0.9655\n",
      "Epoch 103/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1462 - accuracy: 0.9655\n",
      "Epoch 104/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1473 - accuracy: 0.9655\n",
      "Epoch 105/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1426 - accuracy: 0.9724\n",
      "Epoch 106/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1444 - accuracy: 0.9655\n",
      "Epoch 107/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1404 - accuracy: 0.9724\n",
      "Epoch 108/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1401 - accuracy: 0.9517\n",
      "Epoch 109/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1381 - accuracy: 0.9586\n",
      "Epoch 110/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1359 - accuracy: 0.9586\n",
      "Epoch 111/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1334 - accuracy: 0.9724\n",
      "Epoch 112/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1281 - accuracy: 0.9724\n",
      "Epoch 113/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1278 - accuracy: 0.9724\n",
      "Epoch 114/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1242 - accuracy: 0.9793\n",
      "Epoch 115/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1245 - accuracy: 0.9724\n",
      "Epoch 116/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1201 - accuracy: 0.9793\n",
      "Epoch 117/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1247 - accuracy: 0.9586\n",
      "Epoch 118/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1213 - accuracy: 0.9724\n",
      "Epoch 119/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1155 - accuracy: 0.9793\n",
      "Epoch 120/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1190 - accuracy: 0.9793\n",
      "Epoch 121/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1189 - accuracy: 0.9793\n",
      "Epoch 122/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1162 - accuracy: 0.9724\n",
      "Epoch 123/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1162 - accuracy: 0.9724\n",
      "Epoch 124/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1162 - accuracy: 0.9862\n",
      "Epoch 125/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1151 - accuracy: 0.9793\n",
      "Epoch 126/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1126 - accuracy: 0.9793\n",
      "Epoch 127/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1051 - accuracy: 0.9793\n",
      "Epoch 128/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1069 - accuracy: 0.9862\n",
      "Epoch 129/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1034 - accuracy: 0.9724\n",
      "Epoch 130/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1156 - accuracy: 0.9724\n",
      "Epoch 131/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1036 - accuracy: 0.9793\n",
      "Epoch 132/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1026 - accuracy: 0.9862\n",
      "Epoch 133/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1118 - accuracy: 0.9724\n",
      "Epoch 134/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0970 - accuracy: 0.9793\n",
      "Epoch 135/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0985 - accuracy: 0.9862\n",
      "Epoch 136/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1006 - accuracy: 0.9793\n",
      "Epoch 137/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0948 - accuracy: 0.9862\n",
      "Epoch 138/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0937 - accuracy: 0.9793\n",
      "Epoch 139/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0907 - accuracy: 0.9793\n",
      "Epoch 140/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0922 - accuracy: 0.9862\n",
      "Epoch 141/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0903 - accuracy: 0.9793\n",
      "Epoch 142/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0931 - accuracy: 0.9724\n",
      "Epoch 143/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0915 - accuracy: 0.9793\n",
      "Epoch 144/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0907 - accuracy: 0.9862\n",
      "Epoch 145/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0888 - accuracy: 0.9793\n",
      "Epoch 146/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0830 - accuracy: 0.9862\n",
      "Epoch 147/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0811 - accuracy: 0.9793\n",
      "Epoch 148/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0810 - accuracy: 0.9862\n",
      "Epoch 149/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0828 - accuracy: 0.9862\n",
      "Epoch 150/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0912 - accuracy: 0.9862\n",
      "Epoch 151/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0814 - accuracy: 0.9862\n",
      "Epoch 152/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0773 - accuracy: 0.9793\n",
      "Epoch 153/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0766 - accuracy: 0.9862\n",
      "Epoch 154/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0809 - accuracy: 0.9793\n",
      "Epoch 155/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0746 - accuracy: 0.9793\n",
      "Epoch 156/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0737 - accuracy: 0.9862\n",
      "Epoch 157/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0721 - accuracy: 0.9931\n",
      "Epoch 158/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0717 - accuracy: 0.9793\n",
      "Epoch 159/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0731 - accuracy: 0.9793\n",
      "Epoch 160/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0722 - accuracy: 0.9862\n",
      "Epoch 161/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0716 - accuracy: 0.9931\n",
      "Epoch 162/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0686 - accuracy: 0.9931\n",
      "Epoch 163/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0709 - accuracy: 0.9862\n",
      "Epoch 164/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0703 - accuracy: 0.9862\n",
      "Epoch 165/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0655 - accuracy: 0.9862\n",
      "Epoch 166/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0638 - accuracy: 0.9862\n",
      "Epoch 167/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0626 - accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0645 - accuracy: 0.9862\n",
      "Epoch 169/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0671 - accuracy: 0.9931\n",
      "Epoch 170/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0678 - accuracy: 0.9862\n",
      "Epoch 171/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0652 - accuracy: 0.9931\n",
      "Epoch 172/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0619 - accuracy: 0.9931\n",
      "Epoch 173/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0597 - accuracy: 0.9931\n",
      "Epoch 174/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0574 - accuracy: 0.9931\n",
      "Epoch 175/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0565 - accuracy: 0.9931\n",
      "Epoch 176/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0574 - accuracy: 0.9931\n",
      "Epoch 177/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0584 - accuracy: 0.9862\n",
      "Epoch 178/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0633 - accuracy: 0.9862\n",
      "Epoch 179/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0584 - accuracy: 0.9862\n",
      "Epoch 180/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0630 - accuracy: 0.9931\n",
      "Epoch 181/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0529 - accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0509 - accuracy: 0.9931\n",
      "Epoch 183/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0539 - accuracy: 0.9862\n",
      "Epoch 184/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0525 - accuracy: 0.9931\n",
      "Epoch 185/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0524 - accuracy: 0.9931\n",
      "Epoch 186/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0506 - accuracy: 0.9931\n",
      "Epoch 187/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0491 - accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0484 - accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0468 - accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0454 - accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0480 - accuracy: 0.9931\n",
      "Epoch 192/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0443 - accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0447 - accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0458 - accuracy: 0.9931\n",
      "Epoch 195/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0454 - accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0433 - accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0424 - accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0445 - accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0419 - accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0402 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x_train,y_train,epochs=200, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a78b41f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5231 - accuracy: 0.8730\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a2ab37e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8730158805847168"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cd2d7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "425ee0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0692b5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e2eb5548",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_score = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "780f9b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(24, input_dim=60, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ac96747c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step - loss: 0.3102 - accuracy: 0.8333\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5701 - accuracy: 0.8333\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.4141 - accuracy: 0.8333\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.2640 - accuracy: 0.7073\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5982 - accuracy: 0.8049\n",
      ": [0.8809523582458496, 0.8095238208770752, 0.8571428656578064, 0.8780487775802612, 0.7560975551605225, 0.8333333134651184, 0.8333333134651184, 0.8333333134651184, 0.707317054271698, 0.8048780560493469]\n",
      " : 1.638792085647583\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in kfold.split(x):\n",
    "    x_train , x_test = x.iloc[train_index,:], x.iloc[test_index,:]  \n",
    "    y_train , y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    model = model_fn()\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    history=model.fit(x_train, y_train, epochs=200, batch_size=10, verbose=0)\n",
    "    accuracy = model.evaluate(x_test, y_test)[1]\n",
    "    acc_score.append(accuracy)\n",
    "avg_acc_score = sum(acc_score)/5\n",
    "print(':', acc_score)\n",
    "print(' :', avg_acc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fd99ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bdde21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bc0d9480",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('wine.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6f1d9e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,0:12]\n",
    "y = df.iloc[:,12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "28d14404",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "656d1dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_46 (Dense)            (None, 30)                390       \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 12)                372       \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 875\n",
      "Trainable params: 875\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(30,  input_dim=12, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "831aad8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "440851bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 1s 23ms/step - loss: 0.8701 - accuracy: 0.7555 - val_loss: 0.6311 - val_accuracy: 0.6731\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4873 - accuracy: 0.7549 - val_loss: 0.4388 - val_accuracy: 0.7746\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3748 - accuracy: 0.8091 - val_loss: 0.3258 - val_accuracy: 0.8415\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.2944 - accuracy: 0.8956 - val_loss: 0.2830 - val_accuracy: 0.9069\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.2568 - accuracy: 0.9171 - val_loss: 0.2627 - val_accuracy: 0.9046\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.2425 - accuracy: 0.9225 - val_loss: 0.2454 - val_accuracy: 0.9208\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.2326 - accuracy: 0.9297 - val_loss: 0.2372 - val_accuracy: 0.9246\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.2229 - accuracy: 0.9310 - val_loss: 0.2328 - val_accuracy: 0.9238\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.2163 - accuracy: 0.9315 - val_loss: 0.2243 - val_accuracy: 0.9277\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.2092 - accuracy: 0.9358 - val_loss: 0.2182 - val_accuracy: 0.9277\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2020 - accuracy: 0.9356 - val_loss: 0.2122 - val_accuracy: 0.9277\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1942 - accuracy: 0.9366 - val_loss: 0.2107 - val_accuracy: 0.9277\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1873 - accuracy: 0.9374 - val_loss: 0.2132 - val_accuracy: 0.9246\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1826 - accuracy: 0.9379 - val_loss: 0.2162 - val_accuracy: 0.9246\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1811 - accuracy: 0.9397 - val_loss: 0.2129 - val_accuracy: 0.9246\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1789 - accuracy: 0.9376 - val_loss: 0.2099 - val_accuracy: 0.9254\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1775 - accuracy: 0.9379 - val_loss: 0.2079 - val_accuracy: 0.9254\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1758 - accuracy: 0.9379 - val_loss: 0.2072 - val_accuracy: 0.9262\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1739 - accuracy: 0.9397 - val_loss: 0.2065 - val_accuracy: 0.9262\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1724 - accuracy: 0.9402 - val_loss: 0.2045 - val_accuracy: 0.9277\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1711 - accuracy: 0.9410 - val_loss: 0.2038 - val_accuracy: 0.9269\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1706 - accuracy: 0.9392 - val_loss: 0.2028 - val_accuracy: 0.9277\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1700 - accuracy: 0.9407 - val_loss: 0.2019 - val_accuracy: 0.9277\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1689 - accuracy: 0.9394 - val_loss: 0.2002 - val_accuracy: 0.9277\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1674 - accuracy: 0.9410 - val_loss: 0.1998 - val_accuracy: 0.9262\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1666 - accuracy: 0.9407 - val_loss: 0.1993 - val_accuracy: 0.9285\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1661 - accuracy: 0.9425 - val_loss: 0.1983 - val_accuracy: 0.9285\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1652 - accuracy: 0.9415 - val_loss: 0.1981 - val_accuracy: 0.9292\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1645 - accuracy: 0.9428 - val_loss: 0.1968 - val_accuracy: 0.9292\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1638 - accuracy: 0.9430 - val_loss: 0.1949 - val_accuracy: 0.9292\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1631 - accuracy: 0.9430 - val_loss: 0.1946 - val_accuracy: 0.9285\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1622 - accuracy: 0.9430 - val_loss: 0.1935 - val_accuracy: 0.9285\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1618 - accuracy: 0.9433 - val_loss: 0.1932 - val_accuracy: 0.9300\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1611 - accuracy: 0.9425 - val_loss: 0.1926 - val_accuracy: 0.9292\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1604 - accuracy: 0.9433 - val_loss: 0.1922 - val_accuracy: 0.9300\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1604 - accuracy: 0.9430 - val_loss: 0.1906 - val_accuracy: 0.9285\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1592 - accuracy: 0.9443 - val_loss: 0.1894 - val_accuracy: 0.9300\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1584 - accuracy: 0.9428 - val_loss: 0.1887 - val_accuracy: 0.9308\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1580 - accuracy: 0.9435 - val_loss: 0.1888 - val_accuracy: 0.9308\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1575 - accuracy: 0.9428 - val_loss: 0.1872 - val_accuracy: 0.9308\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1568 - accuracy: 0.9448 - val_loss: 0.1864 - val_accuracy: 0.9308\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1565 - accuracy: 0.9433 - val_loss: 0.1867 - val_accuracy: 0.9315\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1571 - accuracy: 0.9423 - val_loss: 0.1848 - val_accuracy: 0.9323\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1554 - accuracy: 0.9438 - val_loss: 0.1863 - val_accuracy: 0.9308\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1548 - accuracy: 0.9430 - val_loss: 0.1842 - val_accuracy: 0.9346\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1544 - accuracy: 0.9451 - val_loss: 0.1854 - val_accuracy: 0.9308\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1543 - accuracy: 0.9433 - val_loss: 0.1821 - val_accuracy: 0.9346\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1515 - accuracy: 0.9443 - val_loss: 0.1818 - val_accuracy: 0.9308\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1515 - accuracy: 0.9441 - val_loss: 0.1803 - val_accuracy: 0.9346\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1510 - accuracy: 0.9433 - val_loss: 0.1785 - val_accuracy: 0.9331\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train, y_train, epochs=50, batch_size=500, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5837d4ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 1ms/step - loss: 0.1648 - accuracy: 0.9392\n",
      "Test accuracy: 0.939230740070343\n"
     ]
    }
   ],
   "source": [
    "score=model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "789980da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_50 (Dense)            (None, 30)                390       \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 12)                372       \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 875\n",
      "Trainable params: 875\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('wine.csv', header=None)\n",
    "\n",
    "X = df.iloc[:,0:12]\n",
    "y = df.iloc[:,12]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(30,  input_dim=12, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "19292f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5e8630a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath=\"{epoch:02d}-{val_accuracy:.4f}.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ff9e5218",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint(filepath=modelpath, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e92cbc81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: saving model to 01-0.7677.hdf5\n",
      "\n",
      "Epoch 2: saving model to 02-0.7677.hdf5\n",
      "\n",
      "Epoch 3: saving model to 03-0.7715.hdf5\n",
      "\n",
      "Epoch 4: saving model to 04-0.8123.hdf5\n",
      "\n",
      "Epoch 5: saving model to 05-0.8554.hdf5\n",
      "\n",
      "Epoch 6: saving model to 06-0.8946.hdf5\n",
      "\n",
      "Epoch 7: saving model to 07-0.9177.hdf5\n",
      "\n",
      "Epoch 8: saving model to 08-0.9192.hdf5\n",
      "\n",
      "Epoch 9: saving model to 09-0.9238.hdf5\n",
      "\n",
      "Epoch 10: saving model to 10-0.9292.hdf5\n",
      "\n",
      "Epoch 11: saving model to 11-0.9315.hdf5\n",
      "\n",
      "Epoch 12: saving model to 12-0.9354.hdf5\n",
      "\n",
      "Epoch 13: saving model to 13-0.9362.hdf5\n",
      "\n",
      "Epoch 14: saving model to 14-0.9362.hdf5\n",
      "\n",
      "Epoch 15: saving model to 15-0.9369.hdf5\n",
      "\n",
      "Epoch 16: saving model to 16-0.9369.hdf5\n",
      "\n",
      "Epoch 17: saving model to 17-0.9362.hdf5\n",
      "\n",
      "Epoch 18: saving model to 18-0.9362.hdf5\n",
      "\n",
      "Epoch 19: saving model to 19-0.9362.hdf5\n",
      "\n",
      "Epoch 20: saving model to 20-0.9369.hdf5\n",
      "\n",
      "Epoch 21: saving model to 21-0.9377.hdf5\n",
      "\n",
      "Epoch 22: saving model to 22-0.9392.hdf5\n",
      "\n",
      "Epoch 23: saving model to 23-0.9392.hdf5\n",
      "\n",
      "Epoch 24: saving model to 24-0.9392.hdf5\n",
      "\n",
      "Epoch 25: saving model to 25-0.9392.hdf5\n",
      "\n",
      "Epoch 26: saving model to 26-0.9392.hdf5\n",
      "\n",
      "Epoch 27: saving model to 27-0.9392.hdf5\n",
      "\n",
      "Epoch 28: saving model to 28-0.9392.hdf5\n",
      "\n",
      "Epoch 29: saving model to 29-0.9392.hdf5\n",
      "\n",
      "Epoch 30: saving model to 30-0.9400.hdf5\n",
      "\n",
      "Epoch 31: saving model to 31-0.9392.hdf5\n",
      "\n",
      "Epoch 32: saving model to 32-0.9408.hdf5\n",
      "\n",
      "Epoch 33: saving model to 33-0.9408.hdf5\n",
      "\n",
      "Epoch 34: saving model to 34-0.9377.hdf5\n",
      "\n",
      "Epoch 35: saving model to 35-0.9385.hdf5\n",
      "\n",
      "Epoch 36: saving model to 36-0.9392.hdf5\n",
      "\n",
      "Epoch 37: saving model to 37-0.9385.hdf5\n",
      "\n",
      "Epoch 38: saving model to 38-0.9392.hdf5\n",
      "\n",
      "Epoch 39: saving model to 39-0.9400.hdf5\n",
      "\n",
      "Epoch 40: saving model to 40-0.9400.hdf5\n",
      "\n",
      "Epoch 41: saving model to 41-0.9400.hdf5\n",
      "\n",
      "Epoch 42: saving model to 42-0.9400.hdf5\n",
      "\n",
      "Epoch 43: saving model to 43-0.9408.hdf5\n",
      "\n",
      "Epoch 44: saving model to 44-0.9400.hdf5\n",
      "\n",
      "Epoch 45: saving model to 45-0.9408.hdf5\n",
      "\n",
      "Epoch 46: saving model to 46-0.9408.hdf5\n",
      "\n",
      "Epoch 47: saving model to 47-0.9408.hdf5\n",
      "\n",
      "Epoch 48: saving model to 48-0.9408.hdf5\n",
      "\n",
      "Epoch 49: saving model to 49-0.9415.hdf5\n",
      "\n",
      "Epoch 50: saving model to 50-0.9415.hdf5\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train, y_train, epochs=50, batch_size=500, validation_split=0.25, verbose=0, callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b16e8e51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.955505</td>\n",
       "      <td>0.746985</td>\n",
       "      <td>1.488024</td>\n",
       "      <td>0.767692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.376937</td>\n",
       "      <td>0.746985</td>\n",
       "      <td>1.036984</td>\n",
       "      <td>0.767692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.960317</td>\n",
       "      <td>0.749038</td>\n",
       "      <td>0.729841</td>\n",
       "      <td>0.771538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.680905</td>\n",
       "      <td>0.773929</td>\n",
       "      <td>0.505956</td>\n",
       "      <td>0.812308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.471411</td>\n",
       "      <td>0.817039</td>\n",
       "      <td>0.360619</td>\n",
       "      <td>0.855385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.359663</td>\n",
       "      <td>0.863228</td>\n",
       "      <td>0.315241</td>\n",
       "      <td>0.894615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.328043</td>\n",
       "      <td>0.893251</td>\n",
       "      <td>0.291927</td>\n",
       "      <td>0.917692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.297491</td>\n",
       "      <td>0.906082</td>\n",
       "      <td>0.264699</td>\n",
       "      <td>0.919231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.276991</td>\n",
       "      <td>0.911727</td>\n",
       "      <td>0.255159</td>\n",
       "      <td>0.923846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.268860</td>\n",
       "      <td>0.912240</td>\n",
       "      <td>0.246886</td>\n",
       "      <td>0.929231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.259928</td>\n",
       "      <td>0.915320</td>\n",
       "      <td>0.240104</td>\n",
       "      <td>0.931538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.252343</td>\n",
       "      <td>0.918912</td>\n",
       "      <td>0.232754</td>\n",
       "      <td>0.935385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.245563</td>\n",
       "      <td>0.919169</td>\n",
       "      <td>0.226863</td>\n",
       "      <td>0.936154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.239495</td>\n",
       "      <td>0.921735</td>\n",
       "      <td>0.221649</td>\n",
       "      <td>0.936154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.234318</td>\n",
       "      <td>0.922504</td>\n",
       "      <td>0.217726</td>\n",
       "      <td>0.936923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.230056</td>\n",
       "      <td>0.925071</td>\n",
       "      <td>0.214231</td>\n",
       "      <td>0.936923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.226546</td>\n",
       "      <td>0.924557</td>\n",
       "      <td>0.211496</td>\n",
       "      <td>0.936154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.223799</td>\n",
       "      <td>0.926097</td>\n",
       "      <td>0.209193</td>\n",
       "      <td>0.936154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.221310</td>\n",
       "      <td>0.925584</td>\n",
       "      <td>0.207243</td>\n",
       "      <td>0.936154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.219116</td>\n",
       "      <td>0.926097</td>\n",
       "      <td>0.205401</td>\n",
       "      <td>0.936923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.217383</td>\n",
       "      <td>0.928150</td>\n",
       "      <td>0.203739</td>\n",
       "      <td>0.937692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.215863</td>\n",
       "      <td>0.928150</td>\n",
       "      <td>0.202222</td>\n",
       "      <td>0.939231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.214424</td>\n",
       "      <td>0.928406</td>\n",
       "      <td>0.201021</td>\n",
       "      <td>0.939231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.213049</td>\n",
       "      <td>0.928663</td>\n",
       "      <td>0.199884</td>\n",
       "      <td>0.939231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.211952</td>\n",
       "      <td>0.928663</td>\n",
       "      <td>0.198938</td>\n",
       "      <td>0.939231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.211213</td>\n",
       "      <td>0.929176</td>\n",
       "      <td>0.197919</td>\n",
       "      <td>0.939231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.210057</td>\n",
       "      <td>0.928663</td>\n",
       "      <td>0.196926</td>\n",
       "      <td>0.939231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.208979</td>\n",
       "      <td>0.928406</td>\n",
       "      <td>0.196406</td>\n",
       "      <td>0.939231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.208242</td>\n",
       "      <td>0.929433</td>\n",
       "      <td>0.195603</td>\n",
       "      <td>0.939231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.206958</td>\n",
       "      <td>0.928920</td>\n",
       "      <td>0.194354</td>\n",
       "      <td>0.940000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.206338</td>\n",
       "      <td>0.929176</td>\n",
       "      <td>0.193678</td>\n",
       "      <td>0.939231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.204942</td>\n",
       "      <td>0.929690</td>\n",
       "      <td>0.192452</td>\n",
       "      <td>0.940769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.204141</td>\n",
       "      <td>0.929946</td>\n",
       "      <td>0.191328</td>\n",
       "      <td>0.940769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.202709</td>\n",
       "      <td>0.930459</td>\n",
       "      <td>0.190997</td>\n",
       "      <td>0.937692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.201763</td>\n",
       "      <td>0.930459</td>\n",
       "      <td>0.189704</td>\n",
       "      <td>0.938462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.201112</td>\n",
       "      <td>0.928920</td>\n",
       "      <td>0.188343</td>\n",
       "      <td>0.939231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.199919</td>\n",
       "      <td>0.930459</td>\n",
       "      <td>0.187773</td>\n",
       "      <td>0.938462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.198788</td>\n",
       "      <td>0.930203</td>\n",
       "      <td>0.186785</td>\n",
       "      <td>0.939231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.197732</td>\n",
       "      <td>0.930716</td>\n",
       "      <td>0.185680</td>\n",
       "      <td>0.940000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.196933</td>\n",
       "      <td>0.931486</td>\n",
       "      <td>0.184821</td>\n",
       "      <td>0.940000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.196036</td>\n",
       "      <td>0.931229</td>\n",
       "      <td>0.184041</td>\n",
       "      <td>0.940000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.195165</td>\n",
       "      <td>0.931999</td>\n",
       "      <td>0.183536</td>\n",
       "      <td>0.940000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.194705</td>\n",
       "      <td>0.931999</td>\n",
       "      <td>0.182627</td>\n",
       "      <td>0.940769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.194333</td>\n",
       "      <td>0.931229</td>\n",
       "      <td>0.182501</td>\n",
       "      <td>0.940000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.192756</td>\n",
       "      <td>0.931999</td>\n",
       "      <td>0.181099</td>\n",
       "      <td>0.940769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.191872</td>\n",
       "      <td>0.931999</td>\n",
       "      <td>0.179899</td>\n",
       "      <td>0.940769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.191498</td>\n",
       "      <td>0.932256</td>\n",
       "      <td>0.179353</td>\n",
       "      <td>0.940769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.190280</td>\n",
       "      <td>0.931742</td>\n",
       "      <td>0.178622</td>\n",
       "      <td>0.940769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.189812</td>\n",
       "      <td>0.931486</td>\n",
       "      <td>0.177314</td>\n",
       "      <td>0.941538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.189010</td>\n",
       "      <td>0.933025</td>\n",
       "      <td>0.176829</td>\n",
       "      <td>0.941538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  accuracy  val_loss  val_accuracy\n",
       "0   1.955505  0.746985  1.488024      0.767692\n",
       "1   1.376937  0.746985  1.036984      0.767692\n",
       "2   0.960317  0.749038  0.729841      0.771538\n",
       "3   0.680905  0.773929  0.505956      0.812308\n",
       "4   0.471411  0.817039  0.360619      0.855385\n",
       "5   0.359663  0.863228  0.315241      0.894615\n",
       "6   0.328043  0.893251  0.291927      0.917692\n",
       "7   0.297491  0.906082  0.264699      0.919231\n",
       "8   0.276991  0.911727  0.255159      0.923846\n",
       "9   0.268860  0.912240  0.246886      0.929231\n",
       "10  0.259928  0.915320  0.240104      0.931538\n",
       "11  0.252343  0.918912  0.232754      0.935385\n",
       "12  0.245563  0.919169  0.226863      0.936154\n",
       "13  0.239495  0.921735  0.221649      0.936154\n",
       "14  0.234318  0.922504  0.217726      0.936923\n",
       "15  0.230056  0.925071  0.214231      0.936923\n",
       "16  0.226546  0.924557  0.211496      0.936154\n",
       "17  0.223799  0.926097  0.209193      0.936154\n",
       "18  0.221310  0.925584  0.207243      0.936154\n",
       "19  0.219116  0.926097  0.205401      0.936923\n",
       "20  0.217383  0.928150  0.203739      0.937692\n",
       "21  0.215863  0.928150  0.202222      0.939231\n",
       "22  0.214424  0.928406  0.201021      0.939231\n",
       "23  0.213049  0.928663  0.199884      0.939231\n",
       "24  0.211952  0.928663  0.198938      0.939231\n",
       "25  0.211213  0.929176  0.197919      0.939231\n",
       "26  0.210057  0.928663  0.196926      0.939231\n",
       "27  0.208979  0.928406  0.196406      0.939231\n",
       "28  0.208242  0.929433  0.195603      0.939231\n",
       "29  0.206958  0.928920  0.194354      0.940000\n",
       "30  0.206338  0.929176  0.193678      0.939231\n",
       "31  0.204942  0.929690  0.192452      0.940769\n",
       "32  0.204141  0.929946  0.191328      0.940769\n",
       "33  0.202709  0.930459  0.190997      0.937692\n",
       "34  0.201763  0.930459  0.189704      0.938462\n",
       "35  0.201112  0.928920  0.188343      0.939231\n",
       "36  0.199919  0.930459  0.187773      0.938462\n",
       "37  0.198788  0.930203  0.186785      0.939231\n",
       "38  0.197732  0.930716  0.185680      0.940000\n",
       "39  0.196933  0.931486  0.184821      0.940000\n",
       "40  0.196036  0.931229  0.184041      0.940000\n",
       "41  0.195165  0.931999  0.183536      0.940000\n",
       "42  0.194705  0.931999  0.182627      0.940769\n",
       "43  0.194333  0.931229  0.182501      0.940000\n",
       "44  0.192756  0.931999  0.181099      0.940769\n",
       "45  0.191872  0.931999  0.179899      0.940769\n",
       "46  0.191498  0.932256  0.179353      0.940769\n",
       "47  0.190280  0.931742  0.178622      0.940769\n",
       "48  0.189812  0.931486  0.177314      0.941538\n",
       "49  0.189010  0.933025  0.176829      0.941538"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_df=pd.DataFrame(history.history)\n",
    "hist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6f3d5705",
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit(X_train, y_train, epochs=2000, batch_size=500, verbose=0, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ae85a131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.188379</td>\n",
       "      <td>0.931999</td>\n",
       "      <td>0.175947</td>\n",
       "      <td>0.941538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.187479</td>\n",
       "      <td>0.933025</td>\n",
       "      <td>0.174747</td>\n",
       "      <td>0.942308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.186055</td>\n",
       "      <td>0.932512</td>\n",
       "      <td>0.174517</td>\n",
       "      <td>0.941538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.184974</td>\n",
       "      <td>0.932769</td>\n",
       "      <td>0.173112</td>\n",
       "      <td>0.942308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.184130</td>\n",
       "      <td>0.934052</td>\n",
       "      <td>0.171704</td>\n",
       "      <td>0.942308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.031822</td>\n",
       "      <td>0.991789</td>\n",
       "      <td>0.055799</td>\n",
       "      <td>0.985385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.031919</td>\n",
       "      <td>0.992302</td>\n",
       "      <td>0.060218</td>\n",
       "      <td>0.985385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.031261</td>\n",
       "      <td>0.992045</td>\n",
       "      <td>0.053598</td>\n",
       "      <td>0.988462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.031686</td>\n",
       "      <td>0.992045</td>\n",
       "      <td>0.054262</td>\n",
       "      <td>0.986923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.033494</td>\n",
       "      <td>0.989992</td>\n",
       "      <td>0.057894</td>\n",
       "      <td>0.986154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          loss  accuracy  val_loss  val_accuracy\n",
       "0     0.188379  0.931999  0.175947      0.941538\n",
       "1     0.187479  0.933025  0.174747      0.942308\n",
       "2     0.186055  0.932512  0.174517      0.941538\n",
       "3     0.184974  0.932769  0.173112      0.942308\n",
       "4     0.184130  0.934052  0.171704      0.942308\n",
       "...        ...       ...       ...           ...\n",
       "1995  0.031822  0.991789  0.055799      0.985385\n",
       "1996  0.031919  0.992302  0.060218      0.985385\n",
       "1997  0.031261  0.992045  0.053598      0.988462\n",
       "1998  0.031686  0.992045  0.054262      0.986923\n",
       "1999  0.033494  0.989992  0.057894      0.986154\n",
       "\n",
       "[2000 rows x 4 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_df=pd.DataFrame(history.history)\n",
    "hist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "362d7d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_vloss=hist_df['val_loss']\n",
    "y_loss=hist_df['loss']\n",
    "x_len = np.arange(len(y_loss))\n",
    "plt.plot(x_len, y_vloss, \"o\", c=\"red\", markersize=2, label='Testset_loss')\n",
    "plt.plot(x_len, y_loss, \"o\", c=\"blue\", markersize=2, label='Trainset_loss')\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c52b8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757d7f44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8faacf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5ac614",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c5e18fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c6976be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_54 (Dense)            (None, 30)                390       \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 12)                372       \n",
      "                                                                 \n",
      " dense_56 (Dense)            (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 875\n",
      "Trainable params: 875\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('wine.csv', header=None)\n",
    "\n",
    "X = df.iloc[:,0:12]\n",
    "y = df.iloc[:,12]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(30,  input_dim=12, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ade64c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a3455985",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath=\"bestmodel.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4afa6d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=0, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dcedff1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "8/8 [==============================] - 1s 24ms/step - loss: 3.0550 - accuracy: 0.3149 - val_loss: 1.1098 - val_accuracy: 0.5754\n",
      "Epoch 2/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6608 - accuracy: 0.7326 - val_loss: 0.3389 - val_accuracy: 0.8608\n",
      "Epoch 3/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2893 - accuracy: 0.8799 - val_loss: 0.2191 - val_accuracy: 0.9131\n",
      "Epoch 4/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2285 - accuracy: 0.9117 - val_loss: 0.2021 - val_accuracy: 0.9246\n",
      "Epoch 5/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2147 - accuracy: 0.9199 - val_loss: 0.1936 - val_accuracy: 0.9292\n",
      "Epoch 6/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2072 - accuracy: 0.9230 - val_loss: 0.1840 - val_accuracy: 0.9377\n",
      "Epoch 7/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2007 - accuracy: 0.9248 - val_loss: 0.1776 - val_accuracy: 0.9377\n",
      "Epoch 8/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1961 - accuracy: 0.9251 - val_loss: 0.1738 - val_accuracy: 0.9369\n",
      "Epoch 9/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1928 - accuracy: 0.9284 - val_loss: 0.1710 - val_accuracy: 0.9415\n",
      "Epoch 10/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1900 - accuracy: 0.9292 - val_loss: 0.1682 - val_accuracy: 0.9423\n",
      "Epoch 11/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1878 - accuracy: 0.9287 - val_loss: 0.1661 - val_accuracy: 0.9415\n",
      "Epoch 12/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1858 - accuracy: 0.9310 - val_loss: 0.1641 - val_accuracy: 0.9431\n",
      "Epoch 13/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1832 - accuracy: 0.9310 - val_loss: 0.1621 - val_accuracy: 0.9446\n",
      "Epoch 14/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1812 - accuracy: 0.9312 - val_loss: 0.1602 - val_accuracy: 0.9446\n",
      "Epoch 15/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1796 - accuracy: 0.9320 - val_loss: 0.1586 - val_accuracy: 0.9446\n",
      "Epoch 16/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1763 - accuracy: 0.9341 - val_loss: 0.1519 - val_accuracy: 0.9454\n",
      "Epoch 17/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1717 - accuracy: 0.9348 - val_loss: 0.1500 - val_accuracy: 0.9446\n",
      "Epoch 18/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1704 - accuracy: 0.9351 - val_loss: 0.1490 - val_accuracy: 0.9500\n",
      "Epoch 19/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1696 - accuracy: 0.9376 - val_loss: 0.1454 - val_accuracy: 0.9446\n",
      "Epoch 20/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1665 - accuracy: 0.9392 - val_loss: 0.1427 - val_accuracy: 0.9477\n",
      "Epoch 21/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1644 - accuracy: 0.9369 - val_loss: 0.1421 - val_accuracy: 0.9515\n",
      "Epoch 22/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1625 - accuracy: 0.9397 - val_loss: 0.1391 - val_accuracy: 0.9469\n",
      "Epoch 23/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1611 - accuracy: 0.9405 - val_loss: 0.1378 - val_accuracy: 0.9446\n",
      "Epoch 24/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1594 - accuracy: 0.9407 - val_loss: 0.1401 - val_accuracy: 0.9523\n",
      "Epoch 25/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1577 - accuracy: 0.9402 - val_loss: 0.1345 - val_accuracy: 0.9469\n",
      "Epoch 26/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1554 - accuracy: 0.9435 - val_loss: 0.1322 - val_accuracy: 0.9492\n",
      "Epoch 27/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1542 - accuracy: 0.9430 - val_loss: 0.1312 - val_accuracy: 0.9523\n",
      "Epoch 28/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1529 - accuracy: 0.9435 - val_loss: 0.1315 - val_accuracy: 0.9469\n",
      "Epoch 29/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1511 - accuracy: 0.9451 - val_loss: 0.1288 - val_accuracy: 0.9515\n",
      "Epoch 30/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1509 - accuracy: 0.9443 - val_loss: 0.1296 - val_accuracy: 0.9546\n",
      "Epoch 31/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1487 - accuracy: 0.9446 - val_loss: 0.1263 - val_accuracy: 0.9538\n",
      "Epoch 32/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1472 - accuracy: 0.9456 - val_loss: 0.1270 - val_accuracy: 0.9492\n",
      "Epoch 33/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1479 - accuracy: 0.9456 - val_loss: 0.1243 - val_accuracy: 0.9523\n",
      "Epoch 34/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1495 - accuracy: 0.9459 - val_loss: 0.1281 - val_accuracy: 0.9562\n",
      "Epoch 35/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1449 - accuracy: 0.9446 - val_loss: 0.1215 - val_accuracy: 0.9546\n",
      "Epoch 36/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1437 - accuracy: 0.9456 - val_loss: 0.1204 - val_accuracy: 0.9531\n",
      "Epoch 37/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1416 - accuracy: 0.9479 - val_loss: 0.1199 - val_accuracy: 0.9546\n",
      "Epoch 38/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1414 - accuracy: 0.9456 - val_loss: 0.1268 - val_accuracy: 0.9592\n",
      "Epoch 39/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1407 - accuracy: 0.9477 - val_loss: 0.1175 - val_accuracy: 0.9562\n",
      "Epoch 40/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1377 - accuracy: 0.9471 - val_loss: 0.1156 - val_accuracy: 0.9569\n",
      "Epoch 41/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1371 - accuracy: 0.9479 - val_loss: 0.1157 - val_accuracy: 0.9592\n",
      "Epoch 42/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1364 - accuracy: 0.9492 - val_loss: 0.1162 - val_accuracy: 0.9615\n",
      "Epoch 43/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1350 - accuracy: 0.9502 - val_loss: 0.1147 - val_accuracy: 0.9538\n",
      "Epoch 44/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1351 - accuracy: 0.9507 - val_loss: 0.1137 - val_accuracy: 0.9554\n",
      "Epoch 45/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1340 - accuracy: 0.9477 - val_loss: 0.1114 - val_accuracy: 0.9592\n",
      "Epoch 46/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1321 - accuracy: 0.9512 - val_loss: 0.1131 - val_accuracy: 0.9538\n",
      "Epoch 47/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1326 - accuracy: 0.9505 - val_loss: 0.1120 - val_accuracy: 0.9662\n",
      "Epoch 48/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1313 - accuracy: 0.9510 - val_loss: 0.1112 - val_accuracy: 0.9662\n",
      "Epoch 49/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1302 - accuracy: 0.9533 - val_loss: 0.1071 - val_accuracy: 0.9577\n",
      "Epoch 50/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1278 - accuracy: 0.9515 - val_loss: 0.1111 - val_accuracy: 0.9654\n",
      "Epoch 51/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1295 - accuracy: 0.9536 - val_loss: 0.1081 - val_accuracy: 0.9654\n",
      "Epoch 52/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1285 - accuracy: 0.9541 - val_loss: 0.1054 - val_accuracy: 0.9577\n",
      "Epoch 53/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1276 - accuracy: 0.9543 - val_loss: 0.1041 - val_accuracy: 0.9592\n",
      "Epoch 54/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1254 - accuracy: 0.9559 - val_loss: 0.1028 - val_accuracy: 0.9608\n",
      "Epoch 55/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1248 - accuracy: 0.9541 - val_loss: 0.1023 - val_accuracy: 0.9638\n",
      "Epoch 56/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1228 - accuracy: 0.9566 - val_loss: 0.1019 - val_accuracy: 0.9608\n",
      "Epoch 57/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1219 - accuracy: 0.9579 - val_loss: 0.1006 - val_accuracy: 0.9654\n",
      "Epoch 58/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1209 - accuracy: 0.9551 - val_loss: 0.1004 - val_accuracy: 0.9654\n",
      "Epoch 59/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1199 - accuracy: 0.9589 - val_loss: 0.1020 - val_accuracy: 0.9600\n",
      "Epoch 60/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1234 - accuracy: 0.9569 - val_loss: 0.1004 - val_accuracy: 0.9685\n",
      "Epoch 61/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1178 - accuracy: 0.9569 - val_loss: 0.0965 - val_accuracy: 0.9646\n",
      "Epoch 62/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1177 - accuracy: 0.9592 - val_loss: 0.0972 - val_accuracy: 0.9685\n",
      "Epoch 63/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1165 - accuracy: 0.9605 - val_loss: 0.0947 - val_accuracy: 0.9662\n",
      "Epoch 64/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1165 - accuracy: 0.9579 - val_loss: 0.0961 - val_accuracy: 0.9685\n",
      "Epoch 65/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1160 - accuracy: 0.9595 - val_loss: 0.0944 - val_accuracy: 0.9677\n",
      "Epoch 66/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1157 - accuracy: 0.9618 - val_loss: 0.0923 - val_accuracy: 0.9677\n",
      "Epoch 67/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1143 - accuracy: 0.9600 - val_loss: 0.0914 - val_accuracy: 0.9677\n",
      "Epoch 68/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1149 - accuracy: 0.9600 - val_loss: 0.0921 - val_accuracy: 0.9692\n",
      "Epoch 69/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1122 - accuracy: 0.9630 - val_loss: 0.0904 - val_accuracy: 0.9677\n",
      "Epoch 70/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1128 - accuracy: 0.9610 - val_loss: 0.0894 - val_accuracy: 0.9685\n",
      "Epoch 71/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1112 - accuracy: 0.9664 - val_loss: 0.0883 - val_accuracy: 0.9692\n",
      "Epoch 72/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1106 - accuracy: 0.9630 - val_loss: 0.0874 - val_accuracy: 0.9708\n",
      "Epoch 73/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1104 - accuracy: 0.9641 - val_loss: 0.0913 - val_accuracy: 0.9677\n",
      "Epoch 74/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1101 - accuracy: 0.9623 - val_loss: 0.0856 - val_accuracy: 0.9700\n",
      "Epoch 75/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1071 - accuracy: 0.9651 - val_loss: 0.0864 - val_accuracy: 0.9715\n",
      "Epoch 76/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1073 - accuracy: 0.9669 - val_loss: 0.0847 - val_accuracy: 0.9731\n",
      "Epoch 77/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1064 - accuracy: 0.9664 - val_loss: 0.0843 - val_accuracy: 0.9715\n",
      "Epoch 78/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1067 - accuracy: 0.9659 - val_loss: 0.0829 - val_accuracy: 0.9738\n",
      "Epoch 79/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1058 - accuracy: 0.9659 - val_loss: 0.0847 - val_accuracy: 0.9692\n",
      "Epoch 80/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1077 - accuracy: 0.9648 - val_loss: 0.0854 - val_accuracy: 0.9692\n",
      "Epoch 81/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1048 - accuracy: 0.9666 - val_loss: 0.0806 - val_accuracy: 0.9746\n",
      "Epoch 82/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1026 - accuracy: 0.9682 - val_loss: 0.0796 - val_accuracy: 0.9762\n",
      "Epoch 83/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1047 - accuracy: 0.9654 - val_loss: 0.0786 - val_accuracy: 0.9769\n",
      "Epoch 84/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1047 - accuracy: 0.9669 - val_loss: 0.0778 - val_accuracy: 0.9777\n",
      "Epoch 85/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1051 - accuracy: 0.9656 - val_loss: 0.0816 - val_accuracy: 0.9738\n",
      "Epoch 86/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1061 - accuracy: 0.9656 - val_loss: 0.0848 - val_accuracy: 0.9738\n",
      "Epoch 87/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1024 - accuracy: 0.9682 - val_loss: 0.0923 - val_accuracy: 0.9723\n",
      "Epoch 88/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1028 - accuracy: 0.9669 - val_loss: 0.0797 - val_accuracy: 0.9746\n",
      "Epoch 89/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0990 - accuracy: 0.9695 - val_loss: 0.0747 - val_accuracy: 0.9769\n",
      "Epoch 90/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0966 - accuracy: 0.9707 - val_loss: 0.0739 - val_accuracy: 0.9800\n",
      "Epoch 91/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0956 - accuracy: 0.9723 - val_loss: 0.0730 - val_accuracy: 0.9800\n",
      "Epoch 92/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0969 - accuracy: 0.9684 - val_loss: 0.0737 - val_accuracy: 0.9754\n",
      "Epoch 93/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0971 - accuracy: 0.9692 - val_loss: 0.0776 - val_accuracy: 0.9700\n",
      "Epoch 94/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0971 - accuracy: 0.9702 - val_loss: 0.0760 - val_accuracy: 0.9715\n",
      "Epoch 95/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0961 - accuracy: 0.9692 - val_loss: 0.0712 - val_accuracy: 0.9800\n",
      "Epoch 96/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0941 - accuracy: 0.9741 - val_loss: 0.0741 - val_accuracy: 0.9731\n",
      "Epoch 97/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0957 - accuracy: 0.9707 - val_loss: 0.0760 - val_accuracy: 0.9692\n",
      "Epoch 98/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0979 - accuracy: 0.9710 - val_loss: 0.0744 - val_accuracy: 0.9715\n",
      "Epoch 99/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0927 - accuracy: 0.9738 - val_loss: 0.0690 - val_accuracy: 0.9808\n",
      "Epoch 100/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0910 - accuracy: 0.9733 - val_loss: 0.0680 - val_accuracy: 0.9808\n",
      "Epoch 101/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0949 - accuracy: 0.9707 - val_loss: 0.0688 - val_accuracy: 0.9815\n",
      "Epoch 102/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0913 - accuracy: 0.9741 - val_loss: 0.0680 - val_accuracy: 0.9808\n",
      "Epoch 103/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0886 - accuracy: 0.9749 - val_loss: 0.0745 - val_accuracy: 0.9754\n",
      "Epoch 104/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0896 - accuracy: 0.9738 - val_loss: 0.0666 - val_accuracy: 0.9800\n",
      "Epoch 105/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0877 - accuracy: 0.9756 - val_loss: 0.0669 - val_accuracy: 0.9815\n",
      "Epoch 106/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0858 - accuracy: 0.9766 - val_loss: 0.0655 - val_accuracy: 0.9815\n",
      "Epoch 107/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0863 - accuracy: 0.9754 - val_loss: 0.0644 - val_accuracy: 0.9808\n",
      "Epoch 108/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0845 - accuracy: 0.9759 - val_loss: 0.0676 - val_accuracy: 0.9777\n",
      "Epoch 109/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0855 - accuracy: 0.9751 - val_loss: 0.0670 - val_accuracy: 0.9785\n",
      "Epoch 110/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0849 - accuracy: 0.9764 - val_loss: 0.0659 - val_accuracy: 0.9800\n",
      "Epoch 111/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0849 - accuracy: 0.9756 - val_loss: 0.0644 - val_accuracy: 0.9831\n",
      "Epoch 112/2000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0857 - accuracy: 0.9774 - val_loss: 0.0617 - val_accuracy: 0.9831\n",
      "Epoch 113/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0825 - accuracy: 0.9766 - val_loss: 0.0636 - val_accuracy: 0.9808\n",
      "Epoch 114/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0848 - accuracy: 0.9761 - val_loss: 0.0604 - val_accuracy: 0.9823\n",
      "Epoch 115/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0846 - accuracy: 0.9764 - val_loss: 0.0598 - val_accuracy: 0.9831\n",
      "Epoch 116/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0830 - accuracy: 0.9769 - val_loss: 0.0597 - val_accuracy: 0.9838\n",
      "Epoch 117/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0845 - accuracy: 0.9766 - val_loss: 0.0588 - val_accuracy: 0.9838\n",
      "Epoch 118/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0814 - accuracy: 0.9772 - val_loss: 0.0677 - val_accuracy: 0.9785\n",
      "Epoch 119/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0828 - accuracy: 0.9749 - val_loss: 0.0624 - val_accuracy: 0.9792\n",
      "Epoch 120/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0816 - accuracy: 0.9761 - val_loss: 0.0683 - val_accuracy: 0.9777\n",
      "Epoch 121/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0811 - accuracy: 0.9759 - val_loss: 0.0604 - val_accuracy: 0.9800\n",
      "Epoch 122/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0791 - accuracy: 0.9759 - val_loss: 0.0641 - val_accuracy: 0.9800\n",
      "Epoch 123/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0792 - accuracy: 0.9779 - val_loss: 0.0566 - val_accuracy: 0.9831\n",
      "Epoch 124/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0796 - accuracy: 0.9777 - val_loss: 0.0600 - val_accuracy: 0.9800\n",
      "Epoch 125/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0783 - accuracy: 0.9792 - val_loss: 0.0565 - val_accuracy: 0.9808\n",
      "Epoch 126/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0780 - accuracy: 0.9777 - val_loss: 0.0554 - val_accuracy: 0.9831\n",
      "Epoch 127/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0769 - accuracy: 0.9784 - val_loss: 0.0548 - val_accuracy: 0.9831\n",
      "Epoch 128/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0757 - accuracy: 0.9787 - val_loss: 0.0557 - val_accuracy: 0.9800\n",
      "Epoch 129/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0760 - accuracy: 0.9792 - val_loss: 0.0646 - val_accuracy: 0.9823\n",
      "Epoch 130/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0774 - accuracy: 0.9784 - val_loss: 0.0549 - val_accuracy: 0.9808\n",
      "Epoch 131/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0794 - accuracy: 0.9792 - val_loss: 0.0588 - val_accuracy: 0.9815\n",
      "Epoch 132/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0763 - accuracy: 0.9787 - val_loss: 0.0557 - val_accuracy: 0.9815\n",
      "Epoch 133/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0773 - accuracy: 0.9774 - val_loss: 0.0550 - val_accuracy: 0.9815\n",
      "Epoch 134/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0807 - accuracy: 0.9769 - val_loss: 0.0591 - val_accuracy: 0.9815\n",
      "Epoch 135/2000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0755 - accuracy: 0.9782 - val_loss: 0.0518 - val_accuracy: 0.9831\n",
      "Epoch 136/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0734 - accuracy: 0.9795 - val_loss: 0.0513 - val_accuracy: 0.9846\n",
      "Epoch 137/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0733 - accuracy: 0.9800 - val_loss: 0.0508 - val_accuracy: 0.9854\n",
      "Epoch 138/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0726 - accuracy: 0.9800 - val_loss: 0.0507 - val_accuracy: 0.9846\n",
      "Epoch 139/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0725 - accuracy: 0.9792 - val_loss: 0.0503 - val_accuracy: 0.9846\n",
      "Epoch 140/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0726 - accuracy: 0.9800 - val_loss: 0.0497 - val_accuracy: 0.9854\n",
      "Epoch 141/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0743 - accuracy: 0.9784 - val_loss: 0.0499 - val_accuracy: 0.9846\n",
      "Epoch 142/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0782 - accuracy: 0.9769 - val_loss: 0.0552 - val_accuracy: 0.9808\n",
      "Epoch 143/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0770 - accuracy: 0.9777 - val_loss: 0.0571 - val_accuracy: 0.9823\n",
      "Epoch 144/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0764 - accuracy: 0.9784 - val_loss: 0.0506 - val_accuracy: 0.9838\n",
      "Epoch 145/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0726 - accuracy: 0.9784 - val_loss: 0.0504 - val_accuracy: 0.9838\n",
      "Epoch 146/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0723 - accuracy: 0.9790 - val_loss: 0.0481 - val_accuracy: 0.9854\n",
      "Epoch 147/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0722 - accuracy: 0.9797 - val_loss: 0.0500 - val_accuracy: 0.9854\n",
      "Epoch 148/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0730 - accuracy: 0.9802 - val_loss: 0.0503 - val_accuracy: 0.9846\n",
      "Epoch 149/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0742 - accuracy: 0.9774 - val_loss: 0.0483 - val_accuracy: 0.9846\n",
      "Epoch 150/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0709 - accuracy: 0.9802 - val_loss: 0.0486 - val_accuracy: 0.9869\n",
      "Epoch 151/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0697 - accuracy: 0.9800 - val_loss: 0.0485 - val_accuracy: 0.9838\n",
      "Epoch 152/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0691 - accuracy: 0.9810 - val_loss: 0.0476 - val_accuracy: 0.9838\n",
      "Epoch 153/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0687 - accuracy: 0.9808 - val_loss: 0.0469 - val_accuracy: 0.9846\n",
      "Epoch 154/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0729 - accuracy: 0.9782 - val_loss: 0.0468 - val_accuracy: 0.9838\n",
      "Epoch 155/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0750 - accuracy: 0.9774 - val_loss: 0.0457 - val_accuracy: 0.9862\n",
      "Epoch 156/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0698 - accuracy: 0.9800 - val_loss: 0.0467 - val_accuracy: 0.9854\n",
      "Epoch 157/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0717 - accuracy: 0.9787 - val_loss: 0.0455 - val_accuracy: 0.9869\n",
      "Epoch 158/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0691 - accuracy: 0.9800 - val_loss: 0.0451 - val_accuracy: 0.9862\n",
      "Epoch 159/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0718 - accuracy: 0.9792 - val_loss: 0.0452 - val_accuracy: 0.9838\n",
      "Epoch 160/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0687 - accuracy: 0.9800 - val_loss: 0.0494 - val_accuracy: 0.9831\n",
      "Epoch 161/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0678 - accuracy: 0.9815 - val_loss: 0.0491 - val_accuracy: 0.9838\n",
      "Epoch 162/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0717 - accuracy: 0.9790 - val_loss: 0.0594 - val_accuracy: 0.9846\n",
      "Epoch 163/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0746 - accuracy: 0.9795 - val_loss: 0.0606 - val_accuracy: 0.9846\n",
      "Epoch 164/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0702 - accuracy: 0.9802 - val_loss: 0.0517 - val_accuracy: 0.9846\n",
      "Epoch 165/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0709 - accuracy: 0.9828 - val_loss: 0.0470 - val_accuracy: 0.9838\n",
      "Epoch 166/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0715 - accuracy: 0.9784 - val_loss: 0.0454 - val_accuracy: 0.9838\n",
      "Epoch 167/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0761 - accuracy: 0.9774 - val_loss: 0.0478 - val_accuracy: 0.9846\n",
      "Epoch 168/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0682 - accuracy: 0.9797 - val_loss: 0.0474 - val_accuracy: 0.9838\n",
      "Epoch 169/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0670 - accuracy: 0.9815 - val_loss: 0.0435 - val_accuracy: 0.9877\n",
      "Epoch 170/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0661 - accuracy: 0.9815 - val_loss: 0.0435 - val_accuracy: 0.9877\n",
      "Epoch 171/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0678 - accuracy: 0.9823 - val_loss: 0.0445 - val_accuracy: 0.9862\n",
      "Epoch 172/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0680 - accuracy: 0.9805 - val_loss: 0.0430 - val_accuracy: 0.9869\n",
      "Epoch 173/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0688 - accuracy: 0.9810 - val_loss: 0.0434 - val_accuracy: 0.9877\n",
      "Epoch 174/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0702 - accuracy: 0.9815 - val_loss: 0.0437 - val_accuracy: 0.9877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0730 - accuracy: 0.9784 - val_loss: 0.0436 - val_accuracy: 0.9854\n",
      "Epoch 176/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0667 - accuracy: 0.9795 - val_loss: 0.0424 - val_accuracy: 0.9877\n",
      "Epoch 177/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0656 - accuracy: 0.9818 - val_loss: 0.0422 - val_accuracy: 0.9877\n",
      "Epoch 178/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0655 - accuracy: 0.9818 - val_loss: 0.0438 - val_accuracy: 0.9862\n",
      "Epoch 179/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0648 - accuracy: 0.9813 - val_loss: 0.0448 - val_accuracy: 0.9862\n",
      "Epoch 180/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0645 - accuracy: 0.9823 - val_loss: 0.0448 - val_accuracy: 0.9854\n",
      "Epoch 181/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0643 - accuracy: 0.9828 - val_loss: 0.0435 - val_accuracy: 0.9869\n",
      "Epoch 182/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0653 - accuracy: 0.9831 - val_loss: 0.0415 - val_accuracy: 0.9877\n",
      "Epoch 183/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0660 - accuracy: 0.9808 - val_loss: 0.0419 - val_accuracy: 0.9869\n",
      "Epoch 184/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0647 - accuracy: 0.9831 - val_loss: 0.0418 - val_accuracy: 0.9869\n",
      "Epoch 185/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0635 - accuracy: 0.9828 - val_loss: 0.0416 - val_accuracy: 0.9885\n",
      "Epoch 186/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0640 - accuracy: 0.9820 - val_loss: 0.0419 - val_accuracy: 0.9869\n",
      "Epoch 187/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0645 - accuracy: 0.9823 - val_loss: 0.0413 - val_accuracy: 0.9885\n",
      "Epoch 188/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0632 - accuracy: 0.9843 - val_loss: 0.0413 - val_accuracy: 0.9862\n",
      "Epoch 189/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0638 - accuracy: 0.9826 - val_loss: 0.0411 - val_accuracy: 0.9869\n",
      "Epoch 190/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0634 - accuracy: 0.9831 - val_loss: 0.0417 - val_accuracy: 0.9877\n",
      "Epoch 191/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0643 - accuracy: 0.9826 - val_loss: 0.0412 - val_accuracy: 0.9869\n",
      "Epoch 192/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0626 - accuracy: 0.9838 - val_loss: 0.0415 - val_accuracy: 0.9877\n",
      "Epoch 193/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0640 - accuracy: 0.9833 - val_loss: 0.0403 - val_accuracy: 0.9877\n",
      "Epoch 194/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0632 - accuracy: 0.9841 - val_loss: 0.0406 - val_accuracy: 0.9869\n",
      "Epoch 195/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0623 - accuracy: 0.9843 - val_loss: 0.0403 - val_accuracy: 0.9885\n",
      "Epoch 196/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0615 - accuracy: 0.9831 - val_loss: 0.0475 - val_accuracy: 0.9900\n",
      "Epoch 197/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0625 - accuracy: 0.9831 - val_loss: 0.0405 - val_accuracy: 0.9862\n",
      "Epoch 198/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0615 - accuracy: 0.9843 - val_loss: 0.0417 - val_accuracy: 0.9877\n",
      "Epoch 199/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0618 - accuracy: 0.9838 - val_loss: 0.0432 - val_accuracy: 0.9877\n",
      "Epoch 200/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0613 - accuracy: 0.9833 - val_loss: 0.0397 - val_accuracy: 0.9877\n",
      "Epoch 201/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0623 - accuracy: 0.9826 - val_loss: 0.0397 - val_accuracy: 0.9869\n",
      "Epoch 202/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0631 - accuracy: 0.9833 - val_loss: 0.0395 - val_accuracy: 0.9885\n",
      "Epoch 203/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0613 - accuracy: 0.9841 - val_loss: 0.0439 - val_accuracy: 0.9862\n",
      "Epoch 204/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0684 - accuracy: 0.9779 - val_loss: 0.0620 - val_accuracy: 0.9769\n",
      "Epoch 205/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0776 - accuracy: 0.9772 - val_loss: 0.0435 - val_accuracy: 0.9869\n",
      "Epoch 206/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0646 - accuracy: 0.9805 - val_loss: 0.0427 - val_accuracy: 0.9877\n",
      "Epoch 207/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0607 - accuracy: 0.9836 - val_loss: 0.0448 - val_accuracy: 0.9877\n",
      "Epoch 208/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0649 - accuracy: 0.9810 - val_loss: 0.0409 - val_accuracy: 0.9877\n",
      "Epoch 209/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0648 - accuracy: 0.9823 - val_loss: 0.0412 - val_accuracy: 0.9877\n",
      "Epoch 210/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0655 - accuracy: 0.9826 - val_loss: 0.0457 - val_accuracy: 0.9854\n",
      "Epoch 211/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0712 - accuracy: 0.9784 - val_loss: 0.0447 - val_accuracy: 0.9854\n",
      "Epoch 212/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0676 - accuracy: 0.9810 - val_loss: 0.0435 - val_accuracy: 0.9862\n",
      "Epoch 213/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0627 - accuracy: 0.9826 - val_loss: 0.0449 - val_accuracy: 0.9854\n",
      "Epoch 214/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0638 - accuracy: 0.9820 - val_loss: 0.0440 - val_accuracy: 0.9862\n",
      "Epoch 215/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0666 - accuracy: 0.9828 - val_loss: 0.0416 - val_accuracy: 0.9877\n",
      "Epoch 216/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0675 - accuracy: 0.9810 - val_loss: 0.0491 - val_accuracy: 0.9823\n",
      "Epoch 217/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0645 - accuracy: 0.9810 - val_loss: 0.0474 - val_accuracy: 0.9838\n",
      "Epoch 218/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0663 - accuracy: 0.9820 - val_loss: 0.0393 - val_accuracy: 0.9862\n",
      "Epoch 219/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0618 - accuracy: 0.9836 - val_loss: 0.0395 - val_accuracy: 0.9877\n",
      "Epoch 220/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0595 - accuracy: 0.9841 - val_loss: 0.0394 - val_accuracy: 0.9877\n",
      "Epoch 221/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0588 - accuracy: 0.9846 - val_loss: 0.0390 - val_accuracy: 0.9877\n",
      "Epoch 222/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0608 - accuracy: 0.9841 - val_loss: 0.0407 - val_accuracy: 0.9877\n",
      "Epoch 223/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0595 - accuracy: 0.9838 - val_loss: 0.0425 - val_accuracy: 0.9885\n",
      "Epoch 224/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0614 - accuracy: 0.9826 - val_loss: 0.0451 - val_accuracy: 0.9892\n",
      "Epoch 225/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0613 - accuracy: 0.9841 - val_loss: 0.0394 - val_accuracy: 0.9877\n",
      "Epoch 226/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0597 - accuracy: 0.9838 - val_loss: 0.0438 - val_accuracy: 0.9892\n",
      "Epoch 227/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0600 - accuracy: 0.9849 - val_loss: 0.0392 - val_accuracy: 0.9877\n",
      "Epoch 228/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0600 - accuracy: 0.9836 - val_loss: 0.0424 - val_accuracy: 0.9877\n",
      "Epoch 229/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0588 - accuracy: 0.9843 - val_loss: 0.0470 - val_accuracy: 0.9900\n",
      "Epoch 230/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0598 - accuracy: 0.9836 - val_loss: 0.0437 - val_accuracy: 0.9892\n",
      "Epoch 231/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0597 - accuracy: 0.9851 - val_loss: 0.0465 - val_accuracy: 0.9908\n",
      "Epoch 232/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0618 - accuracy: 0.9831 - val_loss: 0.0408 - val_accuracy: 0.9862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 233/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0584 - accuracy: 0.9838 - val_loss: 0.0380 - val_accuracy: 0.9885\n",
      "Epoch 234/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0588 - accuracy: 0.9849 - val_loss: 0.0379 - val_accuracy: 0.9892\n",
      "Epoch 235/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0575 - accuracy: 0.9838 - val_loss: 0.0459 - val_accuracy: 0.9900\n",
      "Epoch 236/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0605 - accuracy: 0.9833 - val_loss: 0.0466 - val_accuracy: 0.9892\n",
      "Epoch 237/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0600 - accuracy: 0.9841 - val_loss: 0.0454 - val_accuracy: 0.9892\n",
      "Epoch 238/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0624 - accuracy: 0.9826 - val_loss: 0.0378 - val_accuracy: 0.9885\n",
      "Epoch 239/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0588 - accuracy: 0.9843 - val_loss: 0.0377 - val_accuracy: 0.9892\n",
      "Epoch 240/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0585 - accuracy: 0.9851 - val_loss: 0.0382 - val_accuracy: 0.9885\n",
      "Epoch 241/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0581 - accuracy: 0.9849 - val_loss: 0.0378 - val_accuracy: 0.9892\n",
      "Epoch 242/2000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0577 - accuracy: 0.9849 - val_loss: 0.0386 - val_accuracy: 0.9885\n",
      "Epoch 243/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0600 - accuracy: 0.9838 - val_loss: 0.0394 - val_accuracy: 0.9877\n",
      "Epoch 244/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0579 - accuracy: 0.9841 - val_loss: 0.0395 - val_accuracy: 0.9869\n",
      "Epoch 245/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0590 - accuracy: 0.9859 - val_loss: 0.0379 - val_accuracy: 0.9885\n",
      "Epoch 246/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0580 - accuracy: 0.9843 - val_loss: 0.0403 - val_accuracy: 0.9877\n",
      "Epoch 247/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0578 - accuracy: 0.9841 - val_loss: 0.0358 - val_accuracy: 0.9900\n",
      "Epoch 248/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0571 - accuracy: 0.9849 - val_loss: 0.0465 - val_accuracy: 0.9892\n",
      "Epoch 249/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0568 - accuracy: 0.9831 - val_loss: 0.0374 - val_accuracy: 0.9900\n",
      "Epoch 250/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0561 - accuracy: 0.9846 - val_loss: 0.0363 - val_accuracy: 0.9900\n",
      "Epoch 251/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0564 - accuracy: 0.9851 - val_loss: 0.0402 - val_accuracy: 0.9862\n",
      "Epoch 252/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0563 - accuracy: 0.9849 - val_loss: 0.0366 - val_accuracy: 0.9900\n",
      "Epoch 253/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0583 - accuracy: 0.9820 - val_loss: 0.0420 - val_accuracy: 0.9854\n",
      "Epoch 254/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0577 - accuracy: 0.9836 - val_loss: 0.0363 - val_accuracy: 0.9915\n",
      "Epoch 255/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0574 - accuracy: 0.9838 - val_loss: 0.0410 - val_accuracy: 0.9854\n",
      "Epoch 256/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0573 - accuracy: 0.9843 - val_loss: 0.0406 - val_accuracy: 0.9862\n",
      "Epoch 257/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0611 - accuracy: 0.9823 - val_loss: 0.0369 - val_accuracy: 0.9900\n",
      "Epoch 258/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0589 - accuracy: 0.9836 - val_loss: 0.0385 - val_accuracy: 0.9877\n",
      "Epoch 259/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0560 - accuracy: 0.9861 - val_loss: 0.0389 - val_accuracy: 0.9862\n",
      "Epoch 260/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0595 - accuracy: 0.9828 - val_loss: 0.0367 - val_accuracy: 0.9892\n",
      "Epoch 261/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0634 - accuracy: 0.9800 - val_loss: 0.0362 - val_accuracy: 0.9892\n",
      "Epoch 262/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0592 - accuracy: 0.9820 - val_loss: 0.0361 - val_accuracy: 0.9908\n",
      "Epoch 263/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0596 - accuracy: 0.9828 - val_loss: 0.0402 - val_accuracy: 0.9877\n",
      "Epoch 264/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0623 - accuracy: 0.9823 - val_loss: 0.0551 - val_accuracy: 0.9862\n",
      "Epoch 265/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0587 - accuracy: 0.9838 - val_loss: 0.0445 - val_accuracy: 0.9892\n",
      "Epoch 266/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0614 - accuracy: 0.9828 - val_loss: 0.0537 - val_accuracy: 0.9862\n",
      "Epoch 267/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0604 - accuracy: 0.9808 - val_loss: 0.0603 - val_accuracy: 0.9838\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train, y_train, epochs=2000, batch_size=500, validation_split=0.25, verbose=1, callbacks=[early_stopping_callback,checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0a37d8ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 975us/step - loss: 0.0909 - accuracy: 0.9723\n",
      "Test accuracy: 0.9723076820373535\n"
     ]
    }
   ],
   "source": [
    "score=model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25a5f5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
