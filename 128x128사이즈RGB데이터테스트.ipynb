{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7454c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jg999\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\jg999\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "C:\\Users\\jg999\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import sys\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.optimizers import RMSprop,Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "import os\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d10bb149",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir('D:/siren/도난img')\n",
    "donan_list = []\n",
    "for i in files:\n",
    "    img = Image.open(f'D:/siren/도난img/{i}')\n",
    "    img = img.convert('RGB')\n",
    "    img = img.resize((128, 128))\n",
    "    img = np.array(img)\n",
    "    img = img/255\n",
    "    donan_list.append(img)\n",
    "# 도난 이미지 -> 배열로 변경 후 0-1 사이로 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fa419fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir('D:/siren/응급img')\n",
    "oungub_list = []\n",
    "for i in files:\n",
    "    img = Image.open(f'D:/siren/응급img/{i}')\n",
    "    img = img.convert('RGB')\n",
    "    img = img.resize((128, 128))\n",
    "    img = np.array(img)\n",
    "    img = img/255\n",
    "    oungub_list.append(img)\n",
    "# 응급 이미지 -> 배열로 변경 후 0-1 사이로 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3824e3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir('D:/siren/비상img')\n",
    "bisang_list = []\n",
    "for i in files:\n",
    "    img = Image.open(f'D:/siren/비상img/{i}')\n",
    "    img = img.convert('RGB')\n",
    "    img = img.resize((128, 128))\n",
    "    img = np.array(img)\n",
    "    img = img/255\n",
    "    bisang_list.append(img)\n",
    "# 비상 이미지 -> 배열로 변경 후 0-1 사이로 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43a73576",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir('D:/siren/화재img')\n",
    "fire_list = []\n",
    "for i in files:\n",
    "    img = Image.open(f'D:/siren/화재img/{i}')\n",
    "    img = img.convert('RGB')\n",
    "    img = img.resize((128, 128))\n",
    "    img = np.array(img)\n",
    "    img = img/255\n",
    "    fire_list.append(img)\n",
    "# 비상 이미지 -> 배열로 변경 후 0-1 사이로 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b73994b",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir('D:/siren/기본img')\n",
    "gibon_list = []\n",
    "for i in files:\n",
    "    img = Image.open(f'D:/siren/기본img/{i}')\n",
    "    img = img.convert('RGB')\n",
    "    img = img.resize((128, 128))\n",
    "    img = np.array(img)\n",
    "    img = img/255\n",
    "    gibon_list.append(img)\n",
    "# 기본 이미지 -> 배열로 변경 후 0-1 사이로 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e865a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [0]*len(gibon_list) + [1]*len(donan_list) + [2]*len(oungub_list) + [3]*len(bisang_list)+ [4]*len(fire_list)\n",
    "y = np.array(y)\n",
    "# 결과 값 생성\n",
    "# 도난 0, 응급 1, 비상 2, 기본 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5cef9f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.concatenate([gibon_list, donan_list, oungub_list, bisang_list, fire_list], axis=0)\n",
    "# 배열로 만든 이미지들 합쳐줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13368a25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "757"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fire_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "628501fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ba97ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "# y 데이터 더미로 만듬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802c3ba5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a62e5fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(8, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (128,128,3)))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Conv2D(16, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation = \"relu\"))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# cnn 파라미터 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abefe4f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0bc039cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath=\"cnn_model.hdf5\"\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10)\n",
    "# 체크 포인트 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe9ff00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6e78bc2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 0.72194, saving model to cnn_model.hdf5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.72194 to 0.53388, saving model to cnn_model.hdf5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.53388 to 0.45463, saving model to cnn_model.hdf5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.45463 to 0.37482, saving model to cnn_model.hdf5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.37482 to 0.33348, saving model to cnn_model.hdf5\n",
      "\n",
      "Epoch 6: val_loss improved from 0.33348 to 0.28981, saving model to cnn_model.hdf5\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.28981\n",
      "\n",
      "Epoch 8: val_loss improved from 0.28981 to 0.27649, saving model to cnn_model.hdf5\n",
      "\n",
      "Epoch 9: val_loss improved from 0.27649 to 0.21884, saving model to cnn_model.hdf5\n",
      "\n",
      "Epoch 10: val_loss improved from 0.21884 to 0.21503, saving model to cnn_model.hdf5\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.21503\n",
      "\n",
      "Epoch 12: val_loss improved from 0.21503 to 0.19000, saving model to cnn_model.hdf5\n",
      "\n",
      "Epoch 13: val_loss improved from 0.19000 to 0.17425, saving model to cnn_model.hdf5\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.17425\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.17425\n",
      "\n",
      "Epoch 16: val_loss improved from 0.17425 to 0.16835, saving model to cnn_model.hdf5\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.16835\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.16835\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.16835\n",
      "\n",
      "Epoch 20: val_loss improved from 0.16835 to 0.15976, saving model to cnn_model.hdf5\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.15976\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.15976\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.15976\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.15976\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.15976\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.15976\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.15976\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.15976\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.15976\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.15976\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, validation_split=0.25, epochs=100, batch_size=100, verbose=0, callbacks=[early_stopping_callback,checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "35c8883a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 1s 22ms/step - loss: 0.1613 - accuracy: 0.9444\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1612926423549652, 0.9444444179534912]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)\n",
    "# 정확도 98.8%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6263893c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = gibon_list[10]\n",
    "img = np.expand_dims(img, axis=0)\n",
    "np.argmax(model.predict(img))\n",
    "# 개인 체크용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "a1be269d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 0, 도난 1, 응급 2, 비상 3, 화재 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf75e9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
